{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "AI22BTECH11006 : Ch Kushwanth \n",
    "AI22BTECH11013 : K D V S Aditya\n",
    "AI22BTECH11025 : S Sai Satwik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OlljLGTWPS9"
   },
   "source": [
    "# Testing site for scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9ZfWLDk-3gZ"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WrOqQUHad-y"
   },
   "outputs": [],
   "source": [
    "domain = 'https://www.theoi.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gznvpj4B-55A"
   },
   "outputs": [],
   "source": [
    "URL = 'https://olympioi.com/monsters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "AEYcd8sl-6iB",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "dfc72f00-4e36-4ff8-e13c-004eff8d14a6"
   },
   "outputs": [],
   "source": [
    "response = requests.get(URL)\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully fetched webpage!\")\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ag5uGURe-_pa",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "dad56938-e9c6-48d8-85ff-e21a74935ba7"
   },
   "outputs": [],
   "source": [
    "soup = bs(response.text, 'html.parser')\n",
    "print(soup.body.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "EJKkokiJBFYY",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "8f66790f-507b-4810-ec9c-877ab7e6a120"
   },
   "outputs": [],
   "source": [
    "#obtaining links for greek heroes\n",
    "links = soup.find_all(\"a\")\n",
    "links = [link['href'] for link in links if 'href' in link.attrs]\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyoGoNEqBNY9"
   },
   "outputs": [],
   "source": [
    "# monster_links = [link for link in links if \"monsters\" in link]\n",
    "from urllib.parse import urljoin\n",
    "monster_links = sorted(set(links))\n",
    "monster_links = [urljoin(domain, link) for link in monster_links ]\n",
    "# monster_links = [link for link in monster_links if \"Olympios\" in link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJdExwDrYuAv",
    "outputId": "d81bb773-c656-4ac6-8ba7-f5e0de084243"
   },
   "outputs": [],
   "source": [
    "len(monster_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "HFYMOQT5eZ1R",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "\n",
    "\n",
    "def extract_links(URL):\n",
    "  response = requests.get(URL)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "      print(\"Successfully fetched webpage!\")\n",
    "  else:\n",
    "      print(\"Failed to fetch the webpage. Status code:\", response.status_code)\n",
    "\n",
    "  # Parse the HTML\n",
    "  soup = bs(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "  # Find all <a> tags inside the <main> section\n",
    "  links = soup.find_all('a')\n",
    "  links = [link['href'] for link in links if 'href' in link.attrs]\n",
    "\n",
    "  # Resolve relative URLs to absolute ones\n",
    "  domain = URL\n",
    "  resolved_links = sorted(set(urljoin(domain, link) for link in links))\n",
    "  return resolved_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHXiQ85ocfMr",
    "outputId": "63431d2a-4c21-4067-fedc-0624f4c2c55e"
   },
   "outputs": [],
   "source": [
    "URL = 'https://www.theoi.com/greek-mythology/greek-gods.html'\n",
    "theoi = extract_links(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVeak0qbcxF4"
   },
   "outputs": [],
   "source": [
    "URL = 'https://olympioi.com/monsters'\n",
    "olympioi = extract_links(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meBUDFsydEVM"
   },
   "outputs": [],
   "source": [
    "olympioi = sorted(set(olympioi))\n",
    "# monster_links = [urljoin(domain, link) for link in monster_links ]\n",
    "olympioi = [link for link in olympioi if \"Olympios\" in link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDZ2pBMVZVDj",
    "outputId": "57466503-8f05-4c98-cdd4-a97dc013a87b"
   },
   "outputs": [],
   "source": [
    "#combines links of both monsters and greek heroes obtained from two different sites\n",
    "links = theoi + olympioi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "7K84flyiardv",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "36e77ffa-4eb6-42af-bad0-008d860c1a3d"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "header = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "}\n",
    "#scraping and saving  the informations about links \n",
    "for link in links:\n",
    "    try:\n",
    "        response = requests.get(link, headers=header)\n",
    "        soup = bs(response.content, 'html.parser')\n",
    "\n",
    "        # Extracting titles\n",
    "        title = soup.find('title').get_text(strip=True) if soup.find('title') else \"No Title\"\n",
    "\n",
    "        # Extracting content within <main>\n",
    "        main_content = soup.find('main')\n",
    "        main_text = \".\".join(p.get_text(strip=True) for p in main_content.find_all('p')) if main_content else \"No Main Content\"\n",
    "\n",
    "        # Append to data\n",
    "        data.append([title, link, main_text])\n",
    "        print(f\"Scraped: {title} | URL: {link}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {link}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gF8vKGCzW9Y_"
   },
   "source": [
    "# File saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "4m-7EyVIBq7T",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f38016f9-8b08-4e5f-cedd-26650fb40d4b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Creating a folder in Colab to store the files\n",
    "folder_name = \"Greek-Mythology\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# Creating a files in the specified folder\n",
    "for entry in data:\n",
    "    title, url, info = entry  # Unpack the entry\n",
    "    file_name = title.split(\" -\")[0].strip() + \".txt\"  # Using the text before '-' as the filename\n",
    "    file_path = os.path.join(folder_name, file_name)  \n",
    "\n",
    "    # Create formatted content\n",
    "    content = f\"Title: {title}\\nURL: {url}\\nInfo:\\n{info}\"\n",
    "\n",
    "    # Writing to a text file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)\n",
    "\n",
    "    print(f\"Created file: {file_path}\")\n",
    "\n",
    "\n",
    "import shutil\n",
    "shutil.make_archive(folder_name, 'zip', folder_name)\n",
    "\n",
    "\n",
    "from google.colab import files\n",
    "files.download(f\"{folder_name}.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OieFCH_pduuP"
   },
   "source": [
    "# Loading Data from Saved Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NF6PnQKLVcf2",
    "outputId": "92445454-89ac-4770-88d0-66a3a0d4b4f0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def extract_info_from_drive_files(folder_path):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    data = []  # Initialize a data array\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                file_content = file.read()\n",
    "\n",
    "                lines = file_content.split('\\n')\n",
    "                info_index = lines.index('Info:')\n",
    "                content_after_info = '\\n'.join(lines[info_index+1:]).strip()\n",
    "\n",
    "                data.append(content_after_info)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "folder_path = '/content/drive/MyDrive/Greek Mythology'\n",
    "data = extract_info_from_drive_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_vVwgXSbiTx9",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e73cb824-fbe1-4f29-c598-d9c6eb1bc1ce"
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eu6N1brljw9j"
   },
   "source": [
    "# Stemming and Lementisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LOxzs1GiVgq"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksSHvcxqj8U0",
    "outputId": "c7e3f293-dc00-471f-cd44-a890d30a83f5"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtvoEtTnj8sA"
   },
   "outputs": [],
   "source": [
    "# Initializing tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCsB8J6ZkAQs"
   },
   "outputs": [],
   "source": [
    "cleaned_text = []\n",
    "for text in data:\n",
    "  # Removing special characters and numbers\n",
    "  text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "  cleaned_text .append( re.sub(r'\\s+', ' ', text).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "0L-6fbRmkVuH",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "83b482e8-59b5-4a40-81ee-85a8662bfdb3"
   },
   "outputs": [],
   "source": [
    "cleaned_text[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aN5lEnFSkIP9"
   },
   "outputs": [],
   "source": [
    "sentences,words = [],[]\n",
    "for text in cleaned_text:\n",
    "  # Sentence tokenization\n",
    "  sentences.extend(sent_tokenize(text))\n",
    "  # Word tokenization\n",
    "  words.extend(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D61dqlS6llEs",
    "outputId": "bd9a4c0a-aeaf-4bbb-9faa-ec3ae384b788"
   },
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTcy_0wRkKF1"
   },
   "outputs": [],
   "source": [
    "# Removing stop words\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0dp6m-Bmd28",
    "outputId": "4a1c7999-0038-40d1-c479-fba97b18272e"
   },
   "outputs": [],
   "source": [
    "len(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UW6-CaAPkLpm"
   },
   "outputs": [],
   "source": [
    "# Stemming\n",
    "stemmed_words = [ps.stem(word) for word in filtered_words]\n",
    "\n",
    "# Lemmatization\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keI-pgy4Hdgz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def plot_frequencies(words):\n",
    "    # Counting the frequency of each word\n",
    "    word_freq = Counter(words)\n",
    "\n",
    "    # Geting the top 100 most common words \n",
    "    top_words = word_freq.most_common(100)\n",
    "\n",
    "    # Extracting words and their frequencies\n",
    "    labels, frequencies = zip(*top_words)\n",
    "\n",
    "    # Plotting the bar graph\n",
    "    plt.figure(figsize=(20, 6))  # Set figure size\n",
    "    plt.bar(labels, frequencies, color='skyblue')\n",
    "\n",
    "   \n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Top 100 Most Frequent Words')\n",
    "\n",
    "   \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    \n",
    "    plt.tight_layout()  \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "vz92Gam7Hq-h",
    "outputId": "c82e0f3d-4bdc-4a0f-ac84-66280d0fbeb4"
   },
   "outputs": [],
   "source": [
    "plot_frequencies(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "P1AY6K_qJ0wR",
    "outputId": "012cb3a5-b266-47e1-d28c-114bde903521"
   },
   "outputs": [],
   "source": [
    "plot_frequencies(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zy_kJf6yKYQr"
   },
   "outputs": [],
   "source": [
    "# Calculating the length of each sequence\n",
    "sequence_lengths = [len(seq) for seq in sentences]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "oH-i-nhIMYlS",
    "outputId": "c03850d2-ac1b-4793-b76a-f936a7c4b7d9"
   },
   "outputs": [],
   "source": [
    "# Plotting a histogram of sequence lengths\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(sequence_lengths, color='skyblue', edgecolor='black')\n",
    "\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Sequence Lengths')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "G2vWtv0OMbSb",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "67efb1e2-7e98-4138-a5ce-a583b29beccb"
   },
   "outputs": [],
   "source": [
    "print(f'Average length of sequences : {int(sum(sequence_lengths)/len(sequence_lengths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0g5414qM83X",
    "outputId": "40b5dd96-9a0f-4fc8-d689-0ac7313cb9d4"
   },
   "outputs": [],
   "source": [
    "print(f\"No of unique words : {len(set(stemmed_words))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mk2NiS8gNyZ-",
    "outputId": "3a2b3396-c9eb-48f8-9428-dcf67e832c82"
   },
   "outputs": [],
   "source": [
    "print(f\"No of unique words : {len(set(lemmatized_words))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8KXk-CRNM7T",
    "outputId": "1094cdd7-431a-427e-9285-8652f1337c8c"
   },
   "outputs": [],
   "source": [
    "unique_words = set(stemmed_words)  # Finding unique words\n",
    "total_words = len(stemmed_words)   # Counting total words\n",
    "lexical_diversity = len(unique_words) / total_words if total_words > 0 else 0\n",
    "\n",
    "print(f\"Lexical Diversity: {lexical_diversity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "woV882VkLCO0",
    "outputId": "5650d540-6aee-4bea-fb30-e236128d6b29"
   },
   "outputs": [],
   "source": [
    "unique_words = set(lemmatized_words)  \n",
    "total_words = len(lemmatized_words)   \n",
    "lexical_diversity = len(unique_words) / total_words if total_words > 0 else 0\n",
    "\n",
    "print(f\"Lexical Diversity: {lexical_diversity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if2TMBTLOrTI"
   },
   "source": [
    "# Observations\n",
    "\n",
    "- **Higher Unique Words and Lexical Diversity for Lemmatization:**\n",
    "\n",
    "  Lemmatization considers grammar and maintains meaningful distinctions, so it retains more unique lemmas compared to the cruder process of stemming.\n",
    "  Example: Lemmatization would differentiate \"better\" and \"good,\" but stemming might treat them as the same.\n",
    "-  **Lower Unique Words and Lexical Diversity for Stemming:**\n",
    "\n",
    "  Stemming aggressively reduces words without considering their meaning, leading to overgeneralization"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
